{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:21.339799Z",
     "start_time": "2020-03-02T15:59:16.401995Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 21:25:14.519522: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(65)\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 21:25:15.805583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-18 21:25:15.828107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:15.833410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:15.833533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.122634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.122761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.122842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.122921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 1904 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-07-18 21:25:16.123514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.123624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.123695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.123786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.123860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-18 21:25:16.123920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 1904 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:21.433549Z",
     "start_time": "2020-03-02T15:59:21.341794Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../Data/WeeklyF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.DatetimeIndex(df['Date']).month\n",
    "df['Year']= pd.DatetimeIndex(df['Date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:21.501378Z",
     "start_time": "2020-03-02T15:59:21.461474Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Failure Rate</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Rain</th>\n",
       "      <th>month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.697674</td>\n",
       "      <td>29.803087</td>\n",
       "      <td>0.396749</td>\n",
       "      <td>6.345515</td>\n",
       "      <td>2018.395349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.681469</td>\n",
       "      <td>5.997938</td>\n",
       "      <td>1.283896</td>\n",
       "      <td>3.402972</td>\n",
       "      <td>1.667287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.298571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.165714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>30.867143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>35.587143</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>39.292857</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Failure Rate        Temp        Rain       month         Year\n",
       "count    301.000000  301.000000  301.000000  301.000000   301.000000\n",
       "mean      13.697674   29.803087    0.396749    6.345515  2018.395349\n",
       "std        7.681469    5.997938    1.283896    3.402972     1.667287\n",
       "min        1.000000   19.298571    0.000000    1.000000  2016.000000\n",
       "25%        9.000000   24.165714    0.000000    3.000000  2017.000000\n",
       "50%       12.000000   30.867143    0.000000    6.000000  2018.000000\n",
       "75%       17.000000   35.587143    0.114286    9.000000  2020.000000\n",
       "max       60.000000   39.292857   14.285714   12.000000  2021.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:24.442508Z",
     "start_time": "2020-03-02T15:59:24.423597Z"
    }
   },
   "outputs": [],
   "source": [
    "#df.drop_duplicates(subset=['date_time'], keep=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:25.185523Z",
     "start_time": "2020-03-02T15:59:25.173556Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "validate = df[df['Year'] != 2016][['Failure Rate','Temp']]\n",
    "#df.drop(df['Failure Rate'].tail(10).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:26.107062Z",
     "start_time": "2020-03-02T15:59:26.098083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Failure Rate</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1/3/2016</th>\n",
       "      <td>1</td>\n",
       "      <td>22.224286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/10/2016</th>\n",
       "      <td>17</td>\n",
       "      <td>21.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/17/2016</th>\n",
       "      <td>9</td>\n",
       "      <td>20.708571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/24/2016</th>\n",
       "      <td>8</td>\n",
       "      <td>20.581429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/31/2016</th>\n",
       "      <td>8</td>\n",
       "      <td>21.034286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Failure Rate       Temp\n",
       "Date                              \n",
       "1/3/2016              1  22.224286\n",
       "1/10/2016            17  21.480000\n",
       "1/17/2016             9  20.708571\n",
       "1/24/2016             8  20.581429\n",
       "1/31/2016             8  21.034286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_data = df[['Failure Rate','Temp']]\n",
    "uni_data.index = df['Date']\n",
    "uni_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:27.399605Z",
     "start_time": "2020-03-02T15:59:27.393622Z"
    }
   },
   "outputs": [],
   "source": [
    "#uni_data = uni_data.values\n",
    "scaler_x = preprocessing.MinMaxScaler()\n",
    "x_rescaled = scaler_x.fit_transform(uni_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:28.181517Z",
     "start_time": "2020-03-02T15:59:28.173541Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_prep(dataset, start, end, window, horizon):\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  start = start + window\n",
    "  if end is None:\n",
    "    end = len(dataset) - horizon\n",
    "\n",
    "  for i in range(start, end):\n",
    "\n",
    "    indicesx = range(i-window, i)\n",
    "    X.append(np.reshape(dataset[indicesx,:], (window, 2)))\n",
    "\n",
    "    indicesy = range(i,i+horizon)\n",
    "    y.append(dataset[indicesy,0])\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nrows=df.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T15:59:30.555172Z",
     "start_time": "2020-03-02T15:59:29.541880Z"
    }
   },
   "outputs": [],
   "source": [
    "univar_hist_window = 52\n",
    "horizon = 4\n",
    "TRAIN_SPLIT = Nrows-horizon\n",
    "x_train, y_train = data_prep(x_rescaled, 0, TRAIN_SPLIT,univar_hist_window, horizon)\n",
    "#x_val_uni, y_val_uni = custom_ts_univariate_data_prep(x_rescaled, TRAIN_SPLIT, None,univar_hist_window,horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "years=[2017,2018,2019,2020,2021]\n",
    "split_st=[0,53,105,157,209]#,249\n",
    "split_end=[53,105,157,209,249]\n",
    "Pred = []\n",
    "for i in range(5):\n",
    "    y=years[i]\n",
    "    st=split_st[i]\n",
    "    end=split_end[i]\n",
    "    \n",
    "    v_rescaled= x_rescaled[st+52:end+52]\n",
    "    x_val_multi =np.asarray(x_train[st:end])\n",
    "    y_val_multi =np.asarray(y_train[st:end])\n",
    "    x_train_multi =np.asarray(x_train[:st]+x_train[end:])\n",
    "    y_train_multi =np.asarray(y_train[:st]+y_train[end:])\n",
    "    y_train_multi=y_train_multi.reshape(-1,horizon,1)\n",
    "    y_val_multi=y_val_multi.reshape(-1,horizon,1)\n",
    "    \n",
    "    BATCH_SIZE = 16\n",
    "    BUFFER_SIZE = 64\n",
    "    print(x_val_multi.shape)\n",
    "    print(y_val_multi.shape)\n",
    "    print(x_train_multi.shape)\n",
    "    print(y_train_multi.shape)\n",
    "    train_univariate = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "    val_univariate = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_univariate = val_univariate.batch(BATCH_SIZE).repeat()\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128, input_shape=x_train_multi.shape[-2:], return_sequences=True),\n",
    "    tf.keras.layers.LSTM(units=32),\n",
    "    tf.keras.layers.RepeatVector(y_train_multi.shape[1]), \n",
    "    tf.keras.layers.LSTM(units=64,return_sequences=True),\n",
    "    tf.keras.layers.Dense(40, activation='softmax'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1))\n",
    "])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model_path = r'../Models/Bi__LSTM_FWTemp_excluding_{}.h5'.format(y)\n",
    "    EVALUATION_INTERVAL = 20\n",
    "    EPOCHS = 1000\n",
    "    P=EPOCHS*0.4\n",
    "    history = model.fit(train_univariate, epochs=EPOCHS,steps_per_epoch=EVALUATION_INTERVAL,validation_data=val_univariate, validation_steps=50,verbose =0,\n",
    "                             callbacks =[tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=P, verbose=1, mode='min'),tf.keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)])\n",
    "    \n",
    "    # Recreate the exact same model, including its weights and the optimizer\n",
    "    Trained_model = tf.keras.models.load_model(model_path)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train loss', 'validation loss'], loc='upper left')\n",
    "    plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    uni = df[df['Year']==y-1][['Failure Rate','Temp']]\n",
    "    validatehori = uni.tail(univar_hist_window)\n",
    "    #validatehist = validatehori.values\n",
    "    result = []\n",
    "    # Define Forecast length here\n",
    "    window_len = end-st\n",
    "    val_rescaled= scaler_x.fit_transform(validatehori)\n",
    "\n",
    "    for i in range(1, window_len+1):\n",
    "    \n",
    "        val_rescaled = val_rescaled.reshape((1, univar_hist_window, 2))\n",
    "        Predicted_results = Trained_model.predict(val_rescaled)\n",
    "        #print(val_rescaled.shape)\n",
    "        #print(f'predicted : {Predicted_results}')\n",
    "        result.append(Predicted_results[0][0])\n",
    "        val_rescaled = np.append(val_rescaled[:,1:],[[v_rescaled[i-1,:]]])\n",
    "        val_rescaled = val_rescaled.reshape((1, univar_hist_window, 2))\n",
    "        #print(val_rescaled)\n",
    "    res_arr = np.asarray(result)\n",
    "    res=np.zeros((window_len,2))\n",
    "    res[:,0]=res_arr.reshape(-1)\n",
    "    result_inv_trans = scaler_x.inverse_transform(res)\n",
    "    Pred.extend(result_inv_trans[:,0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T16:04:10.702587Z",
     "start_time": "2020-03-02T16:04:10.669636Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    \n",
    "    def mean_absolute_percentage_error(y_true, y_pred): \n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T16:04:12.860781Z",
     "start_time": "2020-03-02T16:04:12.853804Z"
    }
   },
   "outputs": [],
   "source": [
    "timeseries_evaluation_metrics_func(np.asarray(validate['Failure Rate']),Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T16:04:14.723803Z",
     "start_time": "2020-03-02T16:04:14.471477Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(list(validate.index) ,list(validate['Failure Rate']))\n",
    "plt.plot( list(validate.index),list(Pred))\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.ylabel(\"Failure Rate\")\n",
    "plt.legend(('Actual','predicted'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
